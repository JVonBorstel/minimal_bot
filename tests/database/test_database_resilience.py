#!/usr/bin/env python3
"""
STEP 1.13 - SCENARIO 3: Database Connection Resilience Test

This test proves that the bot can handle database connection failures gracefully
and recover automatically when connections are restored.

CRITICAL TEST - This is a mandatory validation for Step 1.13.
"""

import asyncio
import logging
import os
import sys
import time
import sqlite3
import threading
from typing import Dict, Any, Optional
import pytest # Add pytest

# Add the current directory to Python path for imports
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from config import get_config
from state_models import AppState, UserProfile
from bot_core.my_bot import SQLiteStorage

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('test_database_resilience.log')
    ]
)
logger = logging.getLogger(__name__)

class DatabaseResilienceTester:
    """Test database connection resilience and recovery."""
    
    def __init__(self):
        self.config = get_config()
        self.test_results = []
        self.storage = None
        
    def log_result(self, test_name: str, success: bool, details: str = ""):
        """Log a test result."""
        result = {
            'test': test_name,
            'success': success,
            'details': details,
            'timestamp': time.time()
        }
        self.test_results.append(result)
        status = "‚úÖ PASS" if success else "‚ùå FAIL"
        print(f"{status} {test_name}: {details}")
        logger.info(f"Test result - {test_name}: {'PASS' if success else 'FAIL'} - {details}")
        
    @pytest.mark.asyncio
    async def test_normal_database_operations(self):
        """Establish baseline - normal database operations work."""
        print("üìä TESTING NORMAL DATABASE OPERATIONS BASELINE")
        
        try:
            # Initialize storage
            db_path = "test_resilience.db"
            if os.path.exists(db_path):
                os.remove(db_path)
                
            self.storage = SQLiteStorage(db_path=db_path)
            
            # Create test data
            test_user = UserProfile(
                user_id="resilience_test_user",
                display_name="Resilience Test User",
                email="resilience@test.com",
                assigned_role="DEVELOPER"
            )
            
            test_state = AppState(
                session_id="resilience_test_session",
                selected_model="gemini-1.5-pro",
                current_user=test_user
            )
            
            test_state.add_message(role="user", content="Normal operation test message")
            test_state.add_message(role="assistant", content="Normal operation test response")
            
            # Test write
            write_data = {"resilience_test_session": test_state.model_dump(mode='json')}
            await self.storage.write(write_data)
            
            # Test read
            read_data = await self.storage.read(["resilience_test_session"])
            
            if "resilience_test_session" in read_data:
                retrieved_state = AppState.model_validate(read_data["resilience_test_session"])
                if len(retrieved_state.messages) == 2:
                    self.log_result("Normal Database Operations", True, "Baseline operations working")
                    return True
                else:
                    self.log_result("Normal Database Operations", False, "Data integrity issue")
                    return False
            else:
                self.log_result("Normal Database Operations", False, "Failed to read data")
                return False
                
        except Exception as e:
            self.log_result("Normal Database Operations", False, f"Exception: {str(e)}")
            logger.error("Normal database operations failed", exc_info=True)
            return False
    
    @pytest.mark.asyncio
    async def test_database_corruption_recovery(self):
        """Test handling of database corruption and recovery."""
        print("üí• TESTING DATABASE CORRUPTION RECOVERY")
        
        if not self.storage:
            self.log_result("Database Corruption Recovery", False, "Storage not initialized")
            return False
            
        try:
            # First, ensure we have some data
            test_state = AppState(
                session_id="corruption_test_session",
                selected_model="gemini-1.5-flash"
            )
            test_state.add_message(role="user", content="Pre-corruption test message")
            
            write_data = {"corruption_test_session": test_state.model_dump(mode='json')}
            await self.storage.write(write_data)
            
            # Verify data exists
            read_data = await self.storage.read(["corruption_test_session"])
            if "corruption_test_session" not in read_data:
                self.log_result("Database Corruption Recovery", False, "Failed to write initial data")
                return False
            
            # Close the storage connection
            self.storage.close()
            
            # Simulate database corruption by corrupting the file
            db_path = "test_resilience.db"
            if os.path.exists(db_path):
                # Overwrite part of the database file with garbage
                with open(db_path, 'r+b') as f:
                    f.seek(100)  # Go to position 100
                    f.write(b'CORRUPTED_DATA_GARBAGE_BYTES_TO_BREAK_DATABASE' * 10)
                
                self.log_result("Database Corruption Simulation", True, "Database file corrupted")
            
            # Try to reinitialize storage and see if it handles corruption gracefully
            try:
                self.storage = SQLiteStorage(db_path=db_path)
                
                # Try to read from corrupted database
                corrupt_read_data = await self.storage.read(["corruption_test_session"])
                
                # If this succeeds, the corruption wasn't effective enough
                if corrupt_read_data:
                    self.log_result("Database Corruption Recovery", False, "Database corruption didn't work as expected")
                    return False
                    
            except Exception as corruption_error:
                # Expected - database should fail to read corrupted data
                self.log_result("Database Corruption Detection", True, f"Corruption properly detected: {str(corruption_error)[:100]}")
                
                # Test recovery by recreating database
                if os.path.exists(db_path):
                    os.remove(db_path)
                
                # Reinitialize with fresh database
                self.storage = SQLiteStorage(db_path=db_path)
                
                # Test that new database works
                recovery_state = AppState(
                    session_id="recovery_test_session",
                    selected_model="gemini-1.5-pro"
                )
                recovery_state.add_message(role="user", content="Post-recovery test message")
                
                recovery_data = {"recovery_test_session": recovery_state.model_dump(mode='json')}
                await self.storage.write(recovery_data)
                
                # Verify recovery works
                recovery_read = await self.storage.read(["recovery_test_session"])
                if "recovery_test_session" in recovery_read:
                    self.log_result("Database Corruption Recovery", True, "Successfully recovered from corruption")
                    return True
                else:
                    self.log_result("Database Corruption Recovery", False, "Failed to recover from corruption")
                    return False
            
        except Exception as e:
            self.log_result("Database Corruption Recovery", False, f"Exception: {str(e)}")
            logger.error("Database corruption recovery test failed", exc_info=True)
            return False
    
    @pytest.mark.asyncio
    async def test_concurrent_access_resilience(self):
        """Test database resilience under concurrent access."""
        print("üîÑ TESTING CONCURRENT ACCESS RESILIENCE")
        
        if not self.storage:
            self.log_result("Concurrent Access Resilience", False, "Storage not initialized")
            return False
            
        try:
            async def concurrent_worker(worker_id: int):
                """Worker that performs database operations."""
                operations_completed = 0
                errors_encountered = 0
                
                for i in range(50):  # Each worker does 50 operations
                    try:
                        # Create unique data for this worker
                        worker_state = AppState(
                            session_id=f"concurrent_worker_{worker_id}_session_{i}",
                            selected_model="gemini-1.5-pro"
                        )
                        worker_state.add_message(
                            role="user", 
                            content=f"Concurrent message from worker {worker_id}, operation {i}"
                        )
                        
                        # Write operation
                        write_data = {f"concurrent_worker_{worker_id}_session_{i}": worker_state.model_dump(mode='json')}
                        await self.storage.write(write_data)
                        
                        # Read operation to verify
                        read_data = await self.storage.read([f"concurrent_worker_{worker_id}_session_{i}"])
                        
                        if f"concurrent_worker_{worker_id}_session_{i}" in read_data:
                            operations_completed += 1
                        else:
                            errors_encountered += 1
                            
                        # Small delay to allow other workers
                        await asyncio.sleep(0.01)
                        
                    except Exception as e:
                        errors_encountered += 1
                        logger.warning(f"Worker {worker_id} error in operation {i}: {e}")
                
                return operations_completed, errors_encountered
            
            # Run 10 concurrent workers
            workers = [concurrent_worker(i) for i in range(10)]
            results = await asyncio.gather(*workers, return_exceptions=True)
            
            # Analyze results
            total_completed = 0
            total_errors = 0
            worker_failures = 0
            
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    worker_failures += 1
                    logger.error(f"Worker {i} failed completely: {result}")
                else:
                    completed, errors = result
                    total_completed += completed
                    total_errors += errors
            
            # Calculate success metrics
            total_operations = 10 * 50  # 10 workers √ó 50 operations each
            success_rate = (total_completed / total_operations) * 100
            
            if success_rate > 95 and worker_failures == 0:
                self.log_result(
                    "Concurrent Access Resilience", 
                    True, 
                    f"Success rate: {success_rate:.1f}%, {total_completed}/{total_operations} operations completed"
                )
                return True
            else:
                self.log_result(
                    "Concurrent Access Resilience", 
                    False, 
                    f"Poor success rate: {success_rate:.1f}%, {worker_failures} worker failures"
                )
                return False
                
        except Exception as e:
            self.log_result("Concurrent Access Resilience", False, f"Exception: {str(e)}")
            logger.error("Concurrent access resilience test failed", exc_info=True)
            return False
    
    @pytest.mark.asyncio
    async def test_disk_space_exhaustion_handling(self):
        """Test handling of disk space exhaustion."""
        print("üíæ TESTING DISK SPACE EXHAUSTION HANDLING")
        
        if not self.storage:
            self.log_result("Disk Space Exhaustion Handling", False, "Storage not initialized")
            return False
            
        try:
            # This test is tricky - we can't actually exhaust disk space safely
            # Instead, we'll simulate it by trying to write a very large amount of data
            # and testing error handling
            
            large_content = "X" * 10000  # 10KB per message
            large_messages = []
            
            # Create a state with many large messages
            large_state = AppState(
                session_id="disk_space_test_session",
                selected_model="gemini-1.5-pro"
            )
            
            # Add 1000 large messages (should be ~10MB)
            for i in range(1000):
                large_state.add_message(
                    role="user" if i % 2 == 0 else "assistant",
                    content=f"Large message {i}: {large_content}"
                )
            
            # Try to write the large state
            large_data = {"disk_space_test_session": large_state.model_dump(mode='json')}
            
            try:
                await self.storage.write(large_data)
                
                # If write succeeds, verify we can read it back
                read_data = await self.storage.read(["disk_space_test_session"])
                
                if "disk_space_test_session" in read_data:
                    retrieved_state = AppState.model_validate(read_data["disk_space_test_session"])
                    if len(retrieved_state.messages) == 1000:
                        self.log_result(
                            "Disk Space Exhaustion Handling", 
                            True, 
                            f"Successfully handled large data write ({len(str(large_data))} bytes)"
                        )
                        return True
                    else:
                        self.log_result("Disk Space Exhaustion Handling", False, "Data integrity issue with large write")
                        return False
                else:
                    self.log_result("Disk Space Exhaustion Handling", False, "Failed to read back large data")
                    return False
                    
            except Exception as write_error:
                # If write fails, that's actually OK if it's handled gracefully
                error_msg = str(write_error)
                if "disk" in error_msg.lower() or "space" in error_msg.lower() or "full" in error_msg.lower():
                    self.log_result(
                        "Disk Space Exhaustion Handling", 
                        True, 
                        f"Gracefully handled potential disk space issue: {error_msg[:100]}"
                    )
                    return True
                else:
                    # Re-raise if it's not a disk space related error
                    raise write_error
                    
        except Exception as e:
            self.log_result("Disk Space Exhaustion Handling", False, f"Exception: {str(e)}")
            logger.error("Disk space exhaustion test failed", exc_info=True)
            return False
    
    @pytest.mark.asyncio
    async def test_database_locking_recovery(self):
        """Test recovery from database locking issues."""
        print("üîí TESTING DATABASE LOCKING RECOVERY")
        
        if not self.storage:
            self.log_result("Database Locking Recovery", False, "Storage not initialized")
            return False
            
        try:
            # Create a separate connection that will hold a lock
            db_path = "test_resilience.db"
            blocking_conn = sqlite3.connect(db_path)
            blocking_cursor = blocking_conn.cursor()
            
            # Start a transaction that will lock the database
            blocking_cursor.execute("BEGIN EXCLUSIVE TRANSACTION")
            
            # Insert some data to make the lock more realistic
            blocking_cursor.execute("INSERT OR REPLACE INTO bot_state (namespace, id, data) VALUES (?, ?, ?)", 
                                   ("test", "lock_test", '{"locked": true}'))
            
            self.log_result("Database Locking Simulation", True, "Database locked by external connection")
            
            # Now try to write with our storage (should handle the lock gracefully)
            lock_test_state = AppState(
                session_id="lock_test_session",
                selected_model="gemini-1.5-pro"
            )
            lock_test_state.add_message(role="user", content="Testing during database lock")
            
            lock_data = {"lock_test_session": lock_test_state.model_dump(mode='json')}
            
            # This should either succeed (if SQLiteStorage handles locks well) 
            # or fail gracefully with a timeout
            try:
                start_time = time.time()
                await asyncio.wait_for(self.storage.write(lock_data), timeout=5.0)
                write_time = time.time() - start_time
                
                # If write succeeded despite lock, that's actually good
                self.log_result("Database Locking Recovery", True, f"Write succeeded despite lock in {write_time:.2f}s")
                
            except asyncio.TimeoutError:
                # Timeout is expected behavior when database is locked
                self.log_result("Database Locking Recovery", True, "Properly timed out on locked database")
                
            except Exception as lock_error:
                # Other exceptions might indicate proper lock handling too
                error_msg = str(lock_error)
                if "locked" in error_msg.lower() or "busy" in error_msg.lower():
                    self.log_result("Database Locking Recovery", True, f"Properly handled lock: {error_msg[:100]}")
                else:
                    self.log_result("Database Locking Recovery", False, f"Unexpected error: {error_msg[:100]}")
                    return False
            
            finally:
                # Release the lock
                try:
                    blocking_conn.rollback()
                    blocking_conn.close()
                    self.log_result("Database Lock Release", True, "Released external database lock")
                except:
                    pass
            
            # Now test that operations work after lock is released
            post_lock_state = AppState(
                session_id="post_lock_test_session",
                selected_model="gemini-1.5-pro"
            )
            post_lock_state.add_message(role="user", content="Testing after lock release")
            
            post_lock_data = {"post_lock_test_session": post_lock_state.model_dump(mode='json')}
            await self.storage.write(post_lock_data)
            
            # Verify post-lock write worked
            post_lock_read = await self.storage.read(["post_lock_test_session"])
            if "post_lock_test_session" in post_lock_read:
                self.log_result("Post-Lock Recovery", True, "Operations resumed after lock release")
                return True
            else:
                self.log_result("Post-Lock Recovery", False, "Failed to resume operations after lock")
                return False
                
        except Exception as e:
            self.log_result("Database Locking Recovery", False, f"Exception: {str(e)}")
            logger.error("Database locking recovery test failed", exc_info=True)
            return False
    
    async def cleanup(self):
        """Clean up test resources."""
        print("üßπ CLEANING UP RESILIENCE TEST RESOURCES")
        
        try:
            # Close storage
            if self.storage:
                self.storage.close()
                
            # Remove test database
            test_db = "test_resilience.db"
            if os.path.exists(test_db):
                os.remove(test_db)
                print(f"‚úÖ Removed test database: {test_db}")
                
        except Exception as e:
            print(f"‚ö†Ô∏è Cleanup warning: {e}")
    
    def print_summary(self):
        """Print comprehensive test summary."""
        print("\n" + "="*60)
        print("üìä DATABASE RESILIENCE TEST SUMMARY")
        print("="*60)
        
        total_tests = len(self.test_results)
        passed_tests = sum(1 for r in self.test_results if r['success'])
        failed_tests = total_tests - passed_tests
        
        print(f"Total Tests: {total_tests}")
        print(f"Passed: {passed_tests} ‚úÖ")
        print(f"Failed: {failed_tests} ‚ùå")
        print(f"Success Rate: {(passed_tests/total_tests*100):.1f}%")
        
        print("\nDETAILED RESULTS:")
        for result in self.test_results:
            status = "‚úÖ" if result['success'] else "‚ùå"
            print(f"{status} {result['test']}: {result['details']}")
        
        # Critical test evaluation
        critical_tests = [
            "Normal Database Operations",
            "Database Corruption Recovery",
            "Concurrent Access Resilience",
            "Database Locking Recovery"
        ]
        
        critical_passed = sum(1 for r in self.test_results 
                             if r['test'] in critical_tests and r['success'])
        
        print(f"\nCRITICAL TESTS: {critical_passed}/{len(critical_tests)} passed")
        
        if critical_passed == len(critical_tests):
            print("üéâ ALL CRITICAL TESTS PASSED - Database resilience is working!")
        else:
            print("üö® CRITICAL TESTS FAILED - Database resilience has issues!")
        
        return critical_passed >= 3  # Allow 1 failure out of 4 critical tests

async def main():
    """Main test execution function."""
    print("üöÄ STARTING STEP 1.13 SCENARIO 3: Database Connection Resilience Test")
    print("=" * 70)
    
    tester = DatabaseResilienceTester()
    
    try:
        # Run all resilience tests
        await tester.test_normal_database_operations()
        await tester.test_database_corruption_recovery()
        await tester.test_concurrent_access_resilience()
        await tester.test_disk_space_exhaustion_handling()
        await tester.test_database_locking_recovery()
        
        # Print final summary
        success = tester.print_summary()
        
        if success:
            print("\n‚úÖ SCENARIO 3 COMPLETE: Database resilience validation PASSED")
            return True
        else:
            print("\n‚ùå SCENARIO 3 FAILED: Database resilience validation FAILED")
            return False
            
    except Exception as e:
        print(f"\nüí• SCENARIO 3 CRASHED: {e}")
        logger.error("Main test crashed", exc_info=True)
        return False
    finally:
        await tester.cleanup()

if __name__ == "__main__":
    try:
        result = asyncio.run(main())
        sys.exit(0 if result else 1)
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Test interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\nüí• Fatal error: {e}")
        sys.exit(1) 